---
title: "Computing Assignment 8"
author: "Surplus Value"
date: "15 mars 2018"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE)
```


```{r, echo=FALSE}
library(MASS)
library(broom)
library(modelr)
library(tidyverse)

true_ratio = .3/1.1
Sigma <-matrix(c(1, 0.7, 0.7, 1), 2)


sim_reg <- function(n=100, B=200){
  X <-mvrnorm(n=n,c(0, 0), Sigma = Sigma)
  y <- 1.2 + 0.3*X[,1]+1.1*X[,2]+rnorm(n)
  df <-data_frame(y=y, X1=X[,1], X2=X[,2])
  ## reg
  reg <-lm(y~X1+X2, data=df)
  reg_su <-summary(reg)
  reg_co <-tidy(reg_su)
  co_X1 <- reg_co$estimate[2]
  co_X2 <- reg_co$estimate[3]
  ratio <- co_X1/co_X2
  
  ## Delta
  R <- c(0, 1/co_X2, -co_X1/(co_X2)^2)
  v <-as.numeric(t(R) %*%vcov(reg_su) %*% R)
  
  # W-test
  W_test <- t(ratio-true_ratio) %*% solve(v) %*% (ratio-true_ratio)
  
  ## boot it:
  x_boot <- modelr::bootstrap(df, n=B) %>%
    mutate(reg=map(strap, ~lm(y~X1+X2, data=.)),
           reg_su =map(reg, summary),
           reg_co =map(reg_su, tidy),
           ratio_b =map_dbl(reg_co, ~.$estimate[2]/.$estimate[3]),
           R =map(reg_co, ~c(0, 1/.$estimate[2], .$estimate[2]/.$estimate[3]^2)),
           vcov_b =map2_dbl(reg_su,R,  function(x, R) t(R) %*% vcov(x) %*% R),
           W_test_b =map2_dbl(ratio_b, vcov_b,   ~(.x-true_ratio)^2 /.y),
           W_test_b2 =map2_dbl(ratio_b, vcov_b, function(ratio_b, vcov_b)  t(ratio_b-ratio) %*% solve(vcov_b) %*% (ratio_b-ratio)))

  
  
x_boot2 <- x_boot %>%
  summarise(boot_sd=sd(ratio_b),
            boot_sd_v =mean(sqrt(vcov_b)),
            boot_mean=mean(ratio_b),
            wtest_cval=quantile(W_test_b, 0.95),
            wtest2_cval=quantile(W_test_b2, 0.95))
x_boot2

## results: original Wald and va, and boot aggregates
Results<- data_frame(co_X1=co_X1, co_X2=co_X2, ratio=ratio,
           W_test=as.numeric(W_test),
           v=v) %>%
  bind_cols(x_boot2)

return(Results)
}

sim_reg(100,2)

## do all
file <- "~/Desktop/Ph.D./Econometrics/240A/R Problem Sets /Homework 8/Rdata.csv"

if(!file.exists(file)) {
  MC <- rerun(200, sim_reg(100,200)) %>%
    bind_rows
  write_csv(MC, file)
} else {
  MC <- read_csv(file)
}

  ## size of test
```

```{r echo=TRUE}

MC %>% 
  mutate(test_W_seb = (ratio-true_ratio)^2/boot_sd_v) %>%
  summarise(ratio_mean=mean(ratio), 
            size_W = mean(W_test> qchisq(0.95, df=1)),
            size_boot_se = mean(test_W_seb> qchisq(0.95, df=1)),
            size_boot1 = mean(W_test>wtest_cval),
            size_boot2 = mean(W_test>wtest2_cval),
            sd_MC = sd(W_test),
            sd_boot=mean(boot_sd_v),
            sd_delta=mean(v))



```





```{r, echo = FALSE}

##
## Attaching package: 'MASS'
## The following object is masked from 'package:dplyr':
##
## select

#+ load, message=FALSE

library(MASS)
library(modelr)
library(tidyverse)
## generate data
n <- 100
S <- matrix(c(1, 0.5, 0.5, 1), 2)
set.seed(2018)

X <- mvrnorm(n = n, mu=c(0,0), Sigma=S)
y <- 1.2 + 0.3 * X[,1]+rnorm(n)
data_df <- data_frame(y=y, x1=X[,1], x2=X[,2])
## cross validation
crossval_df <- crossv_kfold(data_df, k = n)
crossval <- crossval_df %>%
  mutate(reg1 = map(train, ~lm(y~x1, data=.)),
         reg2 = map(train, ~lm(y~x1+x2, data=.))) %>%
  gather(model, reg, reg1, reg2) %>%
  mutate(resids_out = map2_dbl(reg, test, ~ predict(.x, newdata=.y)-as_data_frame(.y)$y),
         mse_in = map_dbl(reg, ~mean(residuals(.)^2)),
         mse_out = map_dbl(resids_out, ~mean(.^2))) %>%
  gather(mse, value, mse_in, mse_out)

```

```{r, echo = TRUE}

# Question 2.2.a 
tab <- crossval %>%
  group_by(mse, model) %>%
  summarise(mse_val=mean(value)) %>%
  spread(mse, mse_val)


table=as.data.frame(crossval_df)
crossval=as.data.frame(crossval)
table

```



```{r, echo = FALSE}

# mse_in_sub1=crossval[which(crossval$mse=='mse_in'& crossval$model=='reg1'),]
# mean_in_1=mean(mse_in_sub1$value)
# 
# mse_in_sub2=crossval[which(crossval$mse=='mse_in'& crossval$model=='reg2'),]
# mean_in_2=mean(mse_in_sub2$value)
# 
# 
# mse_out_sub1=crossval[which(crossval$mse=='mse_out'& crossval$model=='reg1'),]
# mean_out_1=mean(mse_out_sub1$value)
# 
# 
# mse_out_sub2=crossval[which(crossval$mse=='mse_out'& crossval$model=='reg2'),]
# mean_out_2=mean(mse_out_sub2$value)
```

```{r, echo = FALSE}

#Question 2.2.3
reg_res<-lm(y~x1, data_df)
reg_res$coefficients
reg_un<-lm(y~x1+x2, data_df)
reg_un$coefficients


r_out_1 <- crossval[1,]$resids_out
r_in_1 <- residuals(reg_res)[1]
h_1 <- ((1-hatvalues(reg_res))^(-1))[1]
c(r_out_1, h_1*r_in_1)

r_out_2 <- crossval[1,]$resids_out
r_in_2 <- residuals(reg_un)[2]
h_2 <- ((1-hatvalues(reg_un))^(-1))[2]
c(r_out_2, h_2*r_in_2)





#'### Question 2.3
mean((1-hatvalues(reg_res))^(-2)*reg_res$residuals^2)


#+ stuff, echo=FALSE

# e_telda_res=as.data.frame(reg_res$residuals)
# names(e_telda_res)= c("e_telda_res")
# e_telda_res$e_telda_res_sq=(e_telda_res$e_telda_res^2)
# mse_total_res=mean(e_telda_res$e_telda_res_sq)
# 
# 
# e_telda_un=as.data.frame(reg_un$residuals)
# names(e_telda_un)= c("e_telda_un")
# e_telda_un$e_telda_un_sq=(e_telda_un$e_telda_un^2)
# mse_total_un=mean(e_telda_un$e_telda_un_sq)
# 
# 
# 
# telda_un=as.data.frame(reg_un$residuals)
# names(telda_un)= c("e_telda_un")
# telda_un$telda_un_sq=(telda_un$telda_un^2)
# mse_total_un=mean(telda_un_sq)

```

#Question 2

#####Part 1

Question 2.1.a The dimension of crossval_df is 100 x 3. The names of the objects are train, test, id. id is scalar, train and test have a list of 3 data frames with 100 elements each, including values of y,x1,x2. 


Question 2.1.b model indicates whether the listed estimated coefficients come from the restricted (model 1) or unrestricted (model  2) model. mse indicates if is the mse of the regression from the data that was left out or the mse of the regression from the rest of the observations (n-1) that were used to test the model. Value contains the value of the corresponding mse.

Question 2.1.c the resid_out is the estimated residual given the y,x1,x2 that were left out each time x. and y. are the values used for the prediction of the model each time.

#####Part 2
Question 2.2.a The in sample mse is greater in the restricted model compared to urestricted. This doesn't mean that the unrestricted model explains more variation of y. It is just the result of the addition of one extra variable. Extra variables reduce mse regardless if they are relevant or not.

Question 2.2.b. The out sample mse of the restricted model is much smaller than the out sample mse of the unrestricted.That is, the true model (restricted) predicts much better the left out observations compared to te urestricted. In general,the smaller the difference between the in sample mse and the out sample mse, the better the performence of the model.

Question 2.2.c. As expected the mse of the regressions that trained the model (in sample mse) is smaller than the mse of the regressions that predicted the model (out sample mse). That happens because the observation that was left out hadn't been taken into account when we fitted the data in the model.

#####Part 3
Question 2.3 For the true model we got exactly the same estimation. However, (probably due to some computational mistake) we didn'tget the same for the unrestricted model.








