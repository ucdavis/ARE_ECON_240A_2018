---
title: "Computing 5"
author: "Hoppenfeld, Mather, Ugo"
date: "2/21/2018"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
rm(list=ls())
library(broom)
library(MASS)
library(tidyverse)
```



```{r definefxns, include = FALSE}

simulate_regs <- function(beta, n){
   x <- mvrnorm (n, c(0,0), rbind(c(1,.7), c(.7,1)))
  e <- rnorm(n, 0,1)
  y <- .2 * x[,1] +  e  + beta*x[,2] 
  
  longreg <-lm(formula = y ~ x[, 1] + x[, 2])
  shortreg <-lm(formula = y ~ x[, 1])

  #pick regression:
   if (.05 > tidy(longreg)$p.value[3] ) {
     spec <- 1
     alpha <- tidy(longreg)$estimate[2]
     t_stat <- tidy(longreg)$statistic[2]
     inCI <- 0.2>confint(longreg)[2,1] & 0.2<confint(longreg)[2,2]
     
   }else {
      spec <- 0
     alpha <- tidy(shortreg)$estimate[2]
     t_stat <- tidy(shortreg)$statistic[2]
     inCI <- 0.2>confint(shortreg)[2,1] & 0.2<confint(longreg)[2,2]  
    
  }
  
  return_vector <- c(coef(longreg)[2], coef(longreg)[3], 0.2>confint(longreg)[2,1] & 0.2<confint(longreg)[2,2], coef(shortreg)[2], 0.2>confint(shortreg)[2,1] & 0.2<confint(shortreg)[2,2], spec, alpha, t_stat, inCI)
  names(return_vector) <- c("long alpha","long beta", "long alpha in CI", "short alpha" , "short alpha in CI", "Specification", "everyday alpha", "everyday t", "everday in CI" )
  return(return_vector)
}


colVars <- function(x, na.rm=FALSE, dims=1, unbiased=TRUE, SumSquares=FALSE,
                    twopass=FALSE) {
  if (SumSquares) return(colSums(x^2, na.rm, dims))
  N <- colSums(!is.na(x), FALSE, dims)
  Nm1 <- if (unbiased) N-1 else N
  if (twopass) {x <- if (dims==length(dim(x))) x - mean(x, na.rm=na.rm) else
                     sweep(x, (dims+1):length(dim(x)), colMeans(x,na.rm,dims))}
  (colSums(x^2, na.rm, dims) - colSums(x, na.rm, dims)^2/N) / Nm1
}
```



```{r Build_Simulations , include = TRUE}
results_table <- c()
raw_results <- c()
betas<- c(0, .16, .24, .50)
simulation_sizes <- c(50,100, 150, 200)


for (beta_coef in betas) {
  for (size in simulation_sizes){
    sim_results <- c()
    for (i in seq(2000)) {
      simulation <- simulate_regs(beta_coef, size)
      sim_results <- rbind( sim_results, simulation )
      raw_results <- rbind(raw_results, c(beta_coef , size, simulation ))
    }
    results_table <- rbind(results_table, c(beta_coef , size, colMeans(sim_results)))
    results_table <- rbind(results_table, c(beta_coef , size, colVars(sim_results)))
    colnames(raw_results)[1] <- "beta"
    colnames(raw_results)[2] <- "n"
  }
  
}
```


# Preliminary Questions
- $P(\hat{\beta} \neq 0) = 0.05$ for any n
- When $\beta = 0$, the post-test estimator will not be consistent
- When $\beta \neq 0$, the post-test estimator will be consistent
- With uncertainty about $\beta$, the post-test estimator is not consistent
- Similarly, $\hat{\alpha}$ is not consistent, but...

# For $\beta = 0$, the restricted model has the lowest variance
```{r Question 2, include = FALSE}
library(knitr)
Q2 <- results_table[c(2,4,6,8), c(3,6,9)]
rownames(Q2) <- c("n = 50", "n = 100", "n = 150", "n = 200")
```

```{r Question 2 Output}
kable(Q2)
```

- With $\beta = 0$, the restriction is true. Since the everyday OLS introduces false negatives, the short regression estimator is more efficient than the everyday OLS.




# Estimator bias

```{r  echo = FALSE}
library(kableExtra)
library(knitr)
bias <- as.data.frame(results_table)
bias <- bias[bias[,1]!=0.00,]
bias$`long alpha bias` <- bias[3] -0.2


bias$`short alpha bias` <- bias$`short alpha` -0.2

bias$`everyday alpha bias` <- bias$`everyday alpha` -0.2

bias <- cbind(bias$V1,bias$V2,bias$`long alpha bias`, bias$`short alpha bias`,bias$`everyday alpha bias`)
colnames(bias)<-cbind("Beta2", "N", "Long alpha bias", "Short alpha bias", "Everyday alpha bias")
odd <- seq(1,23,2)
bias <- bias[odd,]
```

```{r estimator bias}
kable(bias,row.names=FALSE, "latex") %>% 
  kable_styling(latex_options = "scale_down")
```


# Confidence intervals

```{r, echo=FALSE}
ci <- as.data.frame(results_table)

ci <- cbind(ci$V1,ci$V2,ci$`long alpha in CI`,ci$`short alpha in CI`,ci$`everday in CI`)
colnames(ci)<-cbind("Beta2", "N", "Long alpha in CI", "Short alpha in CI", "Everyday alpha in CI")

odd <- seq(1,31,2)
ci <- ci[odd,]

```

```{r confidence intervals}
kable(ci,row.names=FALSE,"latex") %>% 
  kable_styling(latex_options = "scale_down")
```


# Density of standardized distributions

```{r setup variances, include=FALSE}
raw_data <-as.data.frame(raw_results)
raw_data$`adjusted short alpha` <- (raw_data$n)^(.5)*(raw_data$`short alpha` - .2)
raw_data$`adjusted long alpha`  <- (raw_data$n)^(.5)*(raw_data$`long alpha` - .2)
raw_data$`adjusted everyday alpha`  <- (raw_data$n)^(.5)*(raw_data$`everyday alpha` - .2)

#T Test values
test_statistics <- as.data.frame(results_table)
test_statistics <- test_statistics$Specification
odd <- c(seq(1, 31, 8), seq(3, 31, 8), seq(5, 31, 8), seq(7, 31, 8))
test_statistics <- test_statistics[odd]
```


```{r, include= TRUE , echo=FALSE}
ggplot(data = raw_data) + 
  geom_density(aes(`adjusted short alpha`, color = "Restricted")) +
  geom_density(aes(`adjusted long alpha`, color = "Unrestricted")) +
  facet_grid(n~beta)  +
  xlab("Alpha Error")

 

```

The restricted specificiation is biased upwards


#All estimators together:
```{r, include= TRUE , echo=FALSE}
ggplot(data = raw_data) + 
  geom_density(aes(`adjusted short alpha`, color = "Restricted")) +
  geom_density(aes(`adjusted long alpha`, color = "Unrestricted")) +
  geom_density(aes(`adjusted everyday alpha`, color = "Everyday")) +
  facet_grid(n~beta) +
  annotate("text",label= test_statistics, x=-2, y=0.4) +
  xlab("Alpha Error")

 

```
When the sample sizes is large, or the potentially-omitted variable is highly significant, the everyday approaches the unrestricted specification. 
